{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Call\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"Yelp_API\") # put your key here if you don't have a .env file in your main project folder.\n",
    "headers = {'Authorization': 'Bearer %s' % API_KEY}\n",
    "base_url = \"https://api.yelp.com/v3/businesses/search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stadiums/Arenas data folder\n",
    "dataFolder='stadiums_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createFolder(outFolder, cat=False):\n",
    "    # Creates directory for current day of the week, raises an error if already exists.\n",
    "    root_dir = 'json_files'\n",
    "    if cat:\n",
    "        parent_dir = os.path.join(root_dir, \"Category_request\")\n",
    "    else:\n",
    "        parent_dir = os.path.join(root_dir, \"General_request\")\n",
    "        \n",
    "    path = os.path.join(parent_dir, outFolder)\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except:\n",
    "        print('Folder already exists.')\n",
    "        \n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def League(path=dataFolder, cat=False):\n",
    "    today = datetime.today()\n",
    "    liga=input(\"Input value:\\nNFL, NBA, MLB, MLS, NHL: \")\n",
    "    filename=f'{liga}.csv'\n",
    "    filepath=os.path.join(path,filename)\n",
    "    df=pd.read_csv(filepath, encoding='utf-8', dtype={\"Team\": \"string\", \"City\": \"string\", \"State\": \"string\", \"Stadium Name\": \"string\", \n",
    "                                    \"Latitude\": np.float64, \"Longitude\": np.float64})\n",
    "    outputFolder=f'cat_{liga}_{today.day}_{today.month}_{today.year}_{today.hour}h{today.minute}m'\n",
    "    output_path=createFolder(outputFolder, cat)\n",
    "    return df, output_path   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teamLoc(df):\n",
    "    zipi=zip(df[\"Latitude\"], df[\"Longitude\"], df[\"Team\"])\n",
    "    return list(zipi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exception_1(Exception):\n",
    "    \"\"\" Raised if \"total\" is not found in the request \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download the JSON files\n",
    "def downloadJSON(lista, term, radius, path, cat=False):\n",
    "    count_f = 0\n",
    "    # API parameters\n",
    "    if cat:\n",
    "        search_params = {\"term\": term, \"limit\": 20, \"radius\": radius, \"sort_by\": \"rating\",\n",
    "                     \"categories\":(\"sportsbars\",\"pubs\",\"wine_bars\", \"cocktailbars\")}\n",
    "    else:\n",
    "        search_params = {\"term\": term, \"limit\": 20, \"radius\": radius, \"sort_by\": \"rating\"}\n",
    "        \n",
    "    for latitude, longitude, team in lista:\n",
    "\n",
    "        search_params.update({\"latitude\": latitude, \"longitude\": longitude})\n",
    "        response = requests.get(url = base_url, params = search_params, headers = headers).json()\n",
    "        try:\n",
    "\n",
    "            if response['total']== False:\n",
    "                raise Exception_1\n",
    "            elif response['total'] >= 1000:\n",
    "                total = 1000\n",
    "            else:\n",
    "                total = response['total']\n",
    "\n",
    "            for search_offset in range(0, total, 20):\n",
    "\n",
    "                search_params.update({\"offset\": search_offset})\n",
    "                response2 = requests.get(url = base_url, params = search_params, headers = headers).json()\n",
    "                file_name = f'yelp_response_{team}_{search_offset}.json'\n",
    "                output_path = os.path.join(path, file_name)\n",
    "\n",
    "                with open(output_path,'w', encoding = 'utf-8') as f:\n",
    "                    json.dump(response2, f, ensure_ascii=False, indent =4)\n",
    "                f.close()\n",
    "\n",
    "        except Exception_1 as e:\n",
    "            print(\"Error: 'total' not found.\\nPlease try again later.\")\n",
    "            print(e)\n",
    "\n",
    "        print(f'{count_f}, {team} total: {total}')\n",
    "\n",
    "        count_f += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stadium_df, outpath=League(dataFolder, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stadium_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium=teamLoc(stadium_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stadium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "downloadJSON(stadium, \"restaurants\", 3000, outpath, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check json files integrity\n",
    "Sometimes, due to an internal error in Yelp, the YELP API would return an empty file with an error code in it. \n",
    "\n",
    "Print to terminal if the json file has errors or not. \n",
    "\n",
    "If there are files with errors, the above request data needs to be re-run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def JSONcheck(jsonpath):\n",
    "    files_list = os.listdir(jsonpath)\n",
    "    error_list = []\n",
    "    for file in files_list:\n",
    "        open_path = os.path.join(jsonpath, file)\n",
    "        with open(open_path, 'r', encoding = 'utf-8') as f:\n",
    "            contents = json.loads(f.read())\n",
    "            try:\n",
    "                total = contents['total']\n",
    "            except:\n",
    "                print(f\"INTERNAL_ERROR in {file}\")\n",
    "                print(\"Something went wrong internally, please try downloading the json file again later.\\n\")\n",
    "                file = f'{file}'\n",
    "                error_list.append(file)\n",
    "            else:\n",
    "                print(f'\\nNo errors found in the json file:\\n{file}\\n')\n",
    "        \n",
    "    if not error_list:\n",
    "        print(f'No erros in json files.\\nNo files to be removed for the analysis.')\n",
    "    else:\n",
    "        print(f'Files with errors:\\n{error_list}')\n",
    "    return error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list = JSONcheck(outpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tryagain(lista, cat=False):\n",
    "    if cat:\n",
    "        pos=3\n",
    "    else:\n",
    "        pos=2\n",
    "    team_errors=[]\n",
    "    for file in lista:\n",
    "        aux=file.split(\"_\")[pos]\n",
    "        team_errors.append(aux)\n",
    "    return team_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team_errors=tryagain(error_list)\n",
    "team_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to download again the cities with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hoy = datetime.today()\n",
    "# newfolder=f'again_for_errors.{hoy.day}_{hoy.month}_{hoy.year}_{hoy.hour}h{hoy.minute}m'\n",
    "# newpath=createFolder(newfolder)\n",
    "# er_df=stadium_df[stadium_df[\"Team\"].isin(team_errors)]\n",
    "# new_list=teamLoc(er_df)\t\n",
    "# downloadJSON(new_list, \"restaurants\", 3000, newpath, cat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newTry(team_errors, cat=False):\n",
    "    hoy = datetime.today()\n",
    "    newfolder=f'again_for_errors.{hoy.day}_{hoy.month}_{hoy.year}_{hoy.hour}h{hoy.minute}m'\n",
    "    newpath=createFolder(newfolder, cat)\n",
    "    er_df=stadium_df[stadium_df[\"Team\"].isin(team_errors)]\n",
    "    new_list=teamLoc(er_df)\t\n",
    "    downloadJSON(new_list, \"restaurants\", 3000, newpath, cat)\n",
    "    return newpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newerror_list= JSONcheck(newTry(team_errors, cat=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final check\n",
    "error_list2 = JSONcheck(outpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
